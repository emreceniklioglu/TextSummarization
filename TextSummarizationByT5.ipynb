{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "855f7b3b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-11-29T13:02:51.583320Z",
     "iopub.status.busy": "2023-11-29T13:02:51.582829Z",
     "iopub.status.idle": "2023-11-29T13:04:43.373309Z",
     "shell.execute_reply": "2023-11-29T13:04:43.371866Z"
    },
    "id": "855f7b3b",
    "outputId": "c2b64a29-f41d-4f79-a9a9-ac940a0d0cdf",
    "papermill": {
     "duration": 111.840231,
     "end_time": "2023-11-29T13:04:43.375868",
     "exception": false,
     "start_time": "2023-11-29T13:02:51.535637",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fsspec, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.14.4\n",
      "    Uninstalling datasets-2.14.4:\n",
      "      Successfully uninstalled datasets-2.14.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-3.6.0 fsspec-2025.3.0\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.71.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.8)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (2.0.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (5.29.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.2.0)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.31.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2025.3.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.4.26)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m128.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m114.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.15)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.31.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.3\n",
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (2.0.2)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.2.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=139c06756178b81c5cf341f9d27505fad5f4b91f97398ea4ad2fb45d2932cd65\n",
      "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score\n",
      "Successfully installed rouge_score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers\n",
    "!pip install -U datasets\n",
    "!pip install tensorboard\n",
    "!pip install sentencepiece\n",
    "!pip install accelerate\n",
    "!pip install evaluate\n",
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17f4135",
   "metadata": {
    "id": "f17f4135",
    "papermill": {
     "duration": 0.049679,
     "end_time": "2023-11-29T13:04:43.475654",
     "exception": false,
     "start_time": "2023-11-29T13:04:43.425975",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e07f4846",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T13:04:43.638645Z",
     "iopub.status.busy": "2023-11-29T13:04:43.637634Z",
     "iopub.status.idle": "2023-11-29T13:05:05.380931Z",
     "shell.execute_reply": "2023-11-29T13:05:05.380053Z"
    },
    "id": "e07f4846",
    "papermill": {
     "duration": 21.856563,
     "end_time": "2023-11-29T13:05:05.383808",
     "exception": false,
     "start_time": "2023-11-29T13:04:43.527245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pprint\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "from transformers import (\n",
    "    T5Tokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b5335f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T13:05:05.489409Z",
     "iopub.status.busy": "2023-11-29T13:05:05.488425Z",
     "iopub.status.idle": "2023-11-29T13:05:05.494018Z",
     "shell.execute_reply": "2023-11-29T13:05:05.493043Z"
    },
    "id": "3b5335f4",
    "papermill": {
     "duration": 0.060037,
     "end_time": "2023-11-29T13:05:05.496276",
     "exception": false,
     "start_time": "2023-11-29T13:05:05.436239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d05564b",
   "metadata": {
    "id": "5d05564b",
    "papermill": {
     "duration": 0.049217,
     "end_time": "2023-11-29T13:05:05.596127",
     "exception": false,
     "start_time": "2023-11-29T13:05:05.546910",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "xk6vQ-hqU5Y8",
   "metadata": {
    "id": "xk6vQ-hqU5Y8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('/content/drive/MyDrive/news_filtered.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C67T8cmr5fYD",
   "metadata": {
    "id": "C67T8cmr5fYD"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "Fa34o2K15Im9",
   "metadata": {
    "id": "Fa34o2K15Im9"
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "def clean_words(sentence):\n",
    "    sentence = str(sentence).lower()\n",
    "    sentence = unicodedata.normalize('NFKD', sentence).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "    # URL'leri temizle\n",
    "    sentence = re.sub(r\"http[s]?://\\S+\", \"\", sentence)\n",
    "\n",
    "    # Özel karakterler ve rakamlar\n",
    "    sentence = re.sub(r\"[\\[\\]\\\\0-9()\\\"$#%/@;:<>{}`+=~|.!?,-]|\\bcnn\\b\", \"\", sentence)\n",
    "\n",
    "    # Diğer özel karakterler\n",
    "    sentence = re.sub(r\"[&…•♦◆★☆■□▪▫▶◀▲▼]\", \"\", sentence)\n",
    "\n",
    "    # Ekstra boşlukları temizle\n",
    "    sentence = re.sub(r\"\\s+\", \" \", sentence)\n",
    "\n",
    "    # Yeni satırları temizle\n",
    "    sentence = re.sub(r\"\\\\n\", \"\", sentence)\n",
    "\n",
    "    # Baş ve sondaki boşlukları kaldır\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    # Artık tokenize etmiyor ve lemma uygulamıyoruz - tokenizer bu işi yapacak\n",
    "    return sentence\n",
    "dataset['article'] = dataset['article'].apply(clean_words)\n",
    "dataset['highlights'] = dataset['highlights'].apply(clean_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "mDPErd0H6QJd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mDPErd0H6QJd",
    "outputId": "a802d044-445f-4094-e0da-07fb2f0b402b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orijinal metinlerin 85. yüzdelik uzunluğu: 462.0\n",
      "En uzun orijinal metin: 500\n",
      "Ortalama orijinal metin uzunluğu: 356.6\n",
      "\n",
      "Özet metinlerin 85. yüzdelik uzunluğu: 56.0\n",
      "En uzun özet metin: 1026\n",
      "Ortalama özet uzunluğu: 43.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def max_length(short_texts, long_texts, prct=85):\n",
    "    \"\"\"\n",
    "    Metinlerin kelime sayılarını ve uzunluk dağılımlarını analiz eder.\n",
    "\n",
    "    Args:\n",
    "        short_texts: Özet metinleri listesi\n",
    "        long_texts: Orijinal metin listesi\n",
    "        prct: Maksimum uzunluk için kullanılacak yüzdelik değer\n",
    "\n",
    "    Returns:\n",
    "        tuple: Belirlenen yüzdeliğe karşılık gelen uzunluklar (uzun, kısa)\n",
    "    \"\"\"\n",
    "    # Metinlerin kelime sayılarını hesapla\n",
    "    length_longs = [len(text.split()) for text in long_texts]\n",
    "    length_shorts = [len(text.split()) for text in short_texts]\n",
    "\n",
    "    # İstatistikler\n",
    "    long_stats = {\n",
    "        'min': min(length_longs),\n",
    "        'max': max(length_longs),\n",
    "        'mean': np.mean(length_longs),\n",
    "        'median': np.median(length_longs),\n",
    "        'std': np.std(length_longs)\n",
    "    }\n",
    "\n",
    "    short_stats = {\n",
    "        'min': min(length_shorts),\n",
    "        'max': max(length_shorts),\n",
    "        'mean': np.mean(length_shorts),\n",
    "        'median': np.median(length_shorts),\n",
    "        'std': np.std(length_shorts)\n",
    "    }\n",
    "\n",
    "    # Yüzdelik değerleri\n",
    "    percentiles = [50, 75, 85, 90, 95, 99]\n",
    "    for p in percentiles:\n",
    "        long_stats[f'p{p}'] = np.percentile(length_longs, p)\n",
    "        short_stats[f'p{p}'] = np.percentile(length_shorts, p)\n",
    "\n",
    "    # İstenilen yüzdelik değerdeki uzunlukları yazdır\n",
    "    print(f'Orijinal metinlerin {prct}. yüzdelik uzunluğu: {long_stats[f\"p{prct}\"]}')\n",
    "    print(f'En uzun orijinal metin: {long_stats[\"max\"]}')\n",
    "    print(f'Ortalama orijinal metin uzunluğu: {long_stats[\"mean\"]:.1f}')\n",
    "    print()\n",
    "    print(f'Özet metinlerin {prct}. yüzdelik uzunluğu: {short_stats[f\"p{prct}\"]}')\n",
    "    print(f'En uzun özet metin: {short_stats[\"max\"]}')\n",
    "    print(f'Ortalama özet uzunluğu: {short_stats[\"mean\"]:.1f}')\n",
    "    print()\n",
    "\n",
    "    # İstenilen yüzdelik değerdeki uzunlukları döndür\n",
    "    return int(long_stats[f'p{prct}']), int(short_stats[f'p{prct}'])\n",
    "\n",
    "# Metinlerin uzunluk analizi\n",
    "max_len_news, max_len_summary = max_length(dataset['highlights'].to_list(), dataset['article'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "SJGEKU-xeOtN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SJGEKU-xeOtN",
    "outputId": "92185ca7-d41f-44da-a8e5-a08cd1360cd5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetInfo(description='', citation='', homepage='', license='', features={'article': Value(dtype='string', id=None), 'highlights': Value(dtype='string', id=None)}, post_processed=None, supervised_keys=None, builder_name=None, dataset_name=None, config_name=None, version=None, splits=None, download_checksums=None, download_size=None, post_processing_size=None, dataset_size=None, size_in_bytes=None)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# excel veri tipinde olan dataseti Dataset türüne çevir\n",
    "dataset = Dataset.from_pandas(dataset)\n",
    "dataset.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1b3ef04c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T13:05:07.482467Z",
     "iopub.status.busy": "2023-11-29T13:05:07.481480Z",
     "iopub.status.idle": "2023-11-29T13:05:07.496660Z",
     "shell.execute_reply": "2023-11-29T13:05:07.495648Z"
    },
    "id": "1b3ef04c",
    "papermill": {
     "duration": 0.069614,
     "end_time": "2023-11-29T13:05:07.498941",
     "exception": false,
     "start_time": "2023-11-29T13:05:07.429327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_dataset = dataset.train_test_split(test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bacc85a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T13:05:07.603898Z",
     "iopub.status.busy": "2023-11-29T13:05:07.602947Z",
     "iopub.status.idle": "2023-11-29T13:05:07.608025Z",
     "shell.execute_reply": "2023-11-29T13:05:07.606981Z"
    },
    "id": "bacc85a7",
    "papermill": {
     "duration": 0.059713,
     "end_time": "2023-11-29T13:05:07.610298",
     "exception": false,
     "start_time": "2023-11-29T13:05:07.550585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_train = full_dataset['train']\n",
    "dataset_valid = full_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7791ec1d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-11-29T13:05:07.716267Z",
     "iopub.status.busy": "2023-11-29T13:05:07.715871Z",
     "iopub.status.idle": "2023-11-29T13:05:07.721401Z",
     "shell.execute_reply": "2023-11-29T13:05:07.720412Z"
    },
    "id": "7791ec1d",
    "outputId": "b120fc6b-2305-4351-d4d5-9881a4880578",
    "papermill": {
     "duration": 0.062019,
     "end_time": "2023-11-29T13:05:07.724031",
     "exception": false,
     "start_time": "2023-11-29T13:05:07.662012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['article', 'highlights'],\n",
      "    num_rows: 80212\n",
      "})\n",
      "Dataset({\n",
      "    features: ['article', 'highlights'],\n",
      "    num_rows: 20054\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset_train)\n",
    "print(dataset_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "lC22L5cEekw1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lC22L5cEekw1",
    "outputId": "a4c6846e-6b6d-4387-9235-e8a257028cd4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article': 'atletico madrid have opened talks with chelsea over a potential deal for german world cup winner andre schurrle schurrle only joined chelsea last summer for m from bayer leverkusen and has failed to hold down an automatic place atletico expressed an interest last week but are pressing for an answer from chelsea jose mourinho though would prefer to sell other foreign players rather than the versatile forward video scroll down for world cup winning andre schurrle walking on water blues bother atletico madrid are chasing chelsea forward andre schurrle and the yearold would appear to want to stay at stamford bridge after stating he hopes to replicate his success at the world cup with chelsea this season the german forward scored three goals to help his country reach the final in brazil where they edged out argentina in extra time playing for keeps chelsea manager jose mourinho would prefer not to part with the german forward german engineering andre schurrle was part of the germany squad that won the world cup in brazil and shurrle is confident chelsea can usurp manchester city as league champions i want to win titles with chelsea and we have an opportunity this season he told the sun i need to take the experience of this summer and make the next step at chelsea to step up and play a big role this season with the confidence i have right now i feel so confident im tired but feeling better and better will schurrle be part of your fantasy football plans click here to start picking your fantasy football team now theres in prizes including up for grabs every week',\n",
       " 'highlights': 'go la liga champions atletico madrid are in talks with andre schurrle chelsea forward was part of germanys world cup winning team schurrle arrived at stamford bridge from bayer leverkusen for m jose mourinho would prefer to sell a different foreign player stop'}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1hChi_RrtdJA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137,
     "referenced_widgets": [
      "c6192c70d77b487a878913ace668afcb",
      "a92acfd3ab074d5abf394ac0dfe9b7c4",
      "f50981f4f29b469cb223dbc798664c98",
      "988f48c5a9114d468fcd02e77070192c",
      "ebfc15d4b73342ef988b5d233eaba0b4",
      "a2584c9cd4704ffc89a2f731bdf9c9a7",
      "9bc9fb0d0f7a4e90b809dd6527e55416",
      "fe9687e50d34496193eec5ecfcb78591",
      "401f4c6735b647059f7742e2cac5fa96",
      "12ed2a06eeb7406095e436efd86bda9e",
      "4a478e61c4f445b486aaed07114e4ec2",
      "88e91ac31c894f0e847d2a131865c7d6",
      "5a4ba181ed7c40bbb4b63a1dc9d4042f",
      "bd99d53454914c1baf5591151959c61b",
      "7c01bb071f64405ca3e12f6ceda23840",
      "c1b7ba49d06c496681e85fe7ec0736d1",
      "9bfeed9549184972b5a89dc6ae250c4c",
      "e2b0d46ea19446d9a44d162f2e1d74a2",
      "ca5832394e154fe5a1099ef68b48e7a9",
      "1adc512e8ec54469a3e03f016209172a",
      "9f9c066880eb496fbac7e53732b17242",
      "e9026b81332849079592083555205f67"
     ]
    },
    "id": "1hChi_RrtdJA",
    "outputId": "0d23702e-2001-415e-f875-b12d4736d1c1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6192c70d77b487a878913ace668afcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80212 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e91ac31c894f0e847d2a131865c7d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20054 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la liga champions atletico madrid are in talks with andre schurrle chelsea forward was part of germanys world cup winning team schurrle arrived at stamford bridge from bayer leverkusen for m jose mourinho would prefer to sell a different foreign player\n",
      "ancient fishing people in china have built a village on water home to thousands the tanka people named gypsies of the sea live in floating homes and seafood farms\n"
     ]
    }
   ],
   "source": [
    "# dataset_train in highlights sutunundaki textlerin başındaki go kelimesini ve sonundaki stop kelimesini kaldır\n",
    "\n",
    "# highlights sütunundaki \"go\" ve \"stop\" kelimelerini kaldır\n",
    "dataset_train = dataset_train.map(lambda example: {\n",
    "    'highlights': example['highlights'].replace('go ', '').replace(' stop', '')\n",
    "})\n",
    "dataset_valid = dataset_valid.map(lambda example: {\n",
    "    'highlights': example['highlights'].replace('go ', '').replace(' stop', '')\n",
    "})\n",
    "# Değişikliği kontrol etmek için örnek bir satırı yazdır\n",
    "print(dataset_train[1000]['highlights'])\n",
    "print(dataset_valid[1000]['highlights'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043e5c49",
   "metadata": {
    "id": "043e5c49",
    "papermill": {
     "duration": 0.050139,
     "end_time": "2023-11-29T13:05:07.826482",
     "exception": false,
     "start_time": "2023-11-29T13:05:07.776343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf760fe9",
   "metadata": {
    "id": "bf760fe9",
    "papermill": {
     "duration": 0.049171,
     "end_time": "2023-11-29T13:05:08.449381",
     "exception": false,
     "start_time": "2023-11-29T13:05:08.400210",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ffcb012e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T13:05:08.558354Z",
     "iopub.status.busy": "2023-11-29T13:05:08.557478Z",
     "iopub.status.idle": "2023-11-29T13:05:08.562905Z",
     "shell.execute_reply": "2023-11-29T13:05:08.561866Z"
    },
    "id": "ffcb012e",
    "papermill": {
     "duration": 0.06107,
     "end_time": "2023-11-29T13:05:08.565035",
     "exception": false,
     "start_time": "2023-11-29T13:05:08.503965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL = 't5-small'\n",
    "BATCH_SIZE = 16\n",
    "NUM_PROCS = 4\n",
    "EPOCHS = 5\n",
    "OUT_DIR = 'results_t5base'\n",
    "MAX_LENGTH = 512 # Maximum context length to consider while preparing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9becbb",
   "metadata": {
    "id": "8d9becbb",
    "papermill": {
     "duration": 0.052431,
     "end_time": "2023-11-29T13:05:08.670909",
     "exception": false,
     "start_time": "2023-11-29T13:05:08.618478",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c18dcd2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T13:05:08.779039Z",
     "iopub.status.busy": "2023-11-29T13:05:08.778654Z",
     "iopub.status.idle": "2023-11-29T13:05:09.581580Z",
     "shell.execute_reply": "2023-11-29T13:05:09.580518Z"
    },
    "id": "c18dcd2e",
    "papermill": {
     "duration": 0.859621,
     "end_time": "2023-11-29T13:05:09.584289",
     "exception": false,
     "start_time": "2023-11-29T13:05:08.724668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b6c89b9b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393,
     "referenced_widgets": [
      "a0f77c29dc25474b968caec21b0cd7aa",
      "c92e13eeed434e8b991aad4036100944",
      "95ab53d4f1b24cb49c63ec6f1309fe2f",
      "58c7e35ec25d438484c9ede0d4dc8add",
      "e62b9804bda84376b091713dd64fa76a",
      "a68e11356cdf4afa9e3d9e4f7c386559",
      "66ed38607dc94a55b4d6aeeda1b0438b",
      "95c62552816f4973944f9f55e0d57d67",
      "4e57b4f736e040d88e8e42834e0a345d",
      "c20a6fe8887445199d2fea2dd3c1797e",
      "d98ed98ad59744f7a8213eb831a42775",
      "32fe4265efba4377a8bb26f58d32e03d",
      "9e473f124a7143ccbef028cc64c833af",
      "3543d8a685374811b31e49c737fe70ac",
      "aeef3b7b6566481f91fa9a0f14ab0e0a",
      "620048e9bce34e5f9a1bd4a4917e59dc",
      "847c5b99734a45d98e90e2572793d284",
      "c55eda74166f4af1b7375b91b49c8cad",
      "f0683723524449ee85c2c50af9d9c5ab",
      "8cececb93de0410cb42dcfdbf1b7a42a",
      "55345246d4ed46f7a32f54744fa23e97",
      "366ab33291ef422b9cee4156e5906a43"
     ]
    },
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-11-29T13:05:09.693545Z",
     "iopub.status.busy": "2023-11-29T13:05:09.693101Z",
     "iopub.status.idle": "2023-11-29T13:05:15.853801Z",
     "shell.execute_reply": "2023-11-29T13:05:15.852748Z"
    },
    "id": "b6c89b9b",
    "outputId": "3e9bc31b-d02b-4371-875d-d52083ded39b",
    "papermill": {
     "duration": 6.217573,
     "end_time": "2023-11-29T13:05:15.856237",
     "exception": false,
     "start_time": "2023-11-29T13:05:09.638664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0f77c29dc25474b968caec21b0cd7aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/80212 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32fe4265efba4377a8bb26f58d32e03d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/20054 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Function to convert text data into model inputs and targets\n",
    "def preprocess_function(examples):\n",
    "    # Set up the tokenizer for inputs\n",
    "    inputs = [f\"summarize: {article}\" for article in examples['article']]\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=MAX_LENGTH,\n",
    "        truncation=True,\n",
    "        padding='max_length'\n",
    "    )\n",
    "\n",
    "    # Set up the tokenizer for targets\n",
    "    targets = [summary for summary in examples['highlights']]\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            targets,\n",
    "            max_length=MAX_LENGTH,\n",
    "            truncation=True,\n",
    "            padding='max_length'\n",
    "        )\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Apply the function to the whole dataset\n",
    "tokenized_train = dataset_train.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=NUM_PROCS\n",
    ")\n",
    "tokenized_valid = dataset_valid.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=NUM_PROCS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3125a0e4",
   "metadata": {
    "id": "3125a0e4",
    "papermill": {
     "duration": 0.051774,
     "end_time": "2023-11-29T13:05:15.960741",
     "exception": false,
     "start_time": "2023-11-29T13:05:15.908967",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0320f5ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-11-29T13:05:16.066433Z",
     "iopub.status.busy": "2023-11-29T13:05:16.065715Z",
     "iopub.status.idle": "2023-11-29T13:05:29.019654Z",
     "shell.execute_reply": "2023-11-29T13:05:29.018359Z"
    },
    "id": "0320f5ce",
    "outputId": "aa607284-071c-466e-f779-a9a5209a5a1d",
    "papermill": {
     "duration": 13.009353,
     "end_time": "2023-11-29T13:05:29.022043",
     "exception": false,
     "start_time": "2023-11-29T13:05:16.012690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60,506,624 total parameters.\n",
      "60,506,624 training parameters.\n"
     ]
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(MODEL)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# Total parameters and trainable parameters.\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"{total_params:,} total parameters.\")\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"{total_trainable_params:,} training parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e873b864",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T13:05:30.434869Z",
     "iopub.status.busy": "2023-11-29T13:05:30.433956Z",
     "iopub.status.idle": "2023-11-29T13:05:30.439676Z",
     "shell.execute_reply": "2023-11-29T13:05:30.438603Z"
    },
    "id": "e873b864",
    "papermill": {
     "duration": 0.063667,
     "end_time": "2023-11-29T13:05:30.441797",
     "exception": false,
     "start_time": "2023-11-29T13:05:30.378130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    \"\"\"\n",
    "    Original Trainer may have a memory leak.\n",
    "    This is a workaround to avoid storing too many tensors that are not needed.\n",
    "    \"\"\"\n",
    "    pred_ids = torch.argmax(logits[0], dim=-1)\n",
    "    return pred_ids, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb17cbe",
   "metadata": {
    "id": "6eb17cbe",
    "papermill": {
     "duration": 0.053815,
     "end_time": "2023-11-29T13:05:30.549456",
     "exception": false,
     "start_time": "2023-11-29T13:05:30.495641",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8858124b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "execution": {
     "iopub.execute_input": "2023-11-29T13:05:30.655730Z",
     "iopub.status.busy": "2023-11-29T13:05:30.655336Z",
     "iopub.status.idle": "2023-11-29T14:36:01.426493Z",
     "shell.execute_reply": "2023-11-29T14:36:01.425273Z"
    },
    "id": "8858124b",
    "outputId": "20b91279-b5c0-4195-c3cd-e06f6b6744da",
    "papermill": {
     "duration": 5430.828472,
     "end_time": "2023-11-29T14:36:01.430491",
     "exception": false,
     "start_time": "2023-11-29T13:05:30.602019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6265' max='6265' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6265/6265 55:00, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.664700</td>\n",
       "      <td>0.201399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.220800</td>\n",
       "      <td>0.197548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.216900</td>\n",
       "      <td>0.196106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.213900</td>\n",
       "      <td>0.195245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.212200</td>\n",
       "      <td>0.194723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.211400</td>\n",
       "      <td>0.194424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=OUT_DIR,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    fp16=True,  # Karma hassasiyet eğitimi\n",
    "    gradient_accumulation_steps=4,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=OUT_DIR,\n",
    "    logging_steps=1000,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=1000,\n",
    "    save_strategy='epoch',\n",
    "    save_total_limit=2,\n",
    "    report_to='tensorboard',\n",
    "    learning_rate=0.0001,\n",
    "    dataloader_num_workers=4\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_valid,\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    "    #compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "history = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6140f3a3",
   "metadata": {
    "id": "6140f3a3",
    "papermill": {
     "duration": 0.051548,
     "end_time": "2023-11-29T14:41:00.429597",
     "exception": false,
     "start_time": "2023-11-29T14:41:00.378049",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3BJZHBVFmIg8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "3BJZHBVFmIg8",
    "outputId": "f71eb0ac-7fb9-4979-cb63-6a71e14d0c73"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"test_dataset\",\n  \"rows\": 55104,\n  \"fields\": [\n    {\n      \"column\": \"Headline\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 54940,\n        \"samples\": [\n          \"Happy to be back with Salman for Tiger Zinda Hai: Kaif\",\n          \" Lawsuit claims Oculus Co-founder spread fake origin story\",\n          \"Gambhir only Indian to make 100s in 5 straight Tests\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Short\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 54997,\n        \"samples\": [\n          \"An Australian couple who own a tropical island resort in Micronesia has decided to give it away in lottery rather than sell it to the highest bidder. The lottery kicked off in April, and so far 55,500 people from 150 countries have bought tickets which start from $49. The lottery for the 16-bed resort will be drawn on Tuesday.\",\n          \"Over 200 rail accidents out of 292, from 2012-13 to January 2016, were caused due to the failure of railway staff as per the data of the Railway Ministry. The data suggested that action was being taken against 542 employees for their negligence and penalties were imposed in over 500 cases based on investigations by Commission of Railway Safety (CRS).\",\n          \"A 1400-km long optical fibre cable has been built connecting the two most precise optical atomic clocks in Europe, located in Germany and France. This marks the first and most accurate comparison of atomic clocks across national borders, a feat that may allow time-sensitive scientific experiments like observing changes in the values of fundamental physical constants over time.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Source \",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1471,\n        \"samples\": [\n          \"RTI ratings\",\n          \"Wakehealth\",\n          \"Human Rights Watch\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Time \",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1405,\n        \"samples\": [\n          \"03:03:00\",\n          \"16:04:00\",\n          \"15:18:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Publish Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2016-01-19 00:00:00\",\n        \"max\": \"2017-03-26 00:00:00\",\n        \"num_unique_values\": 433,\n        \"samples\": [\n          \"2016-01-26 00:00:00\",\n          \"2017-01-10 00:00:00\",\n          \"2016-09-26 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "test_dataset"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-0c9a1eaa-75fb-45b9-a1ff-8027e98abd58\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Short</th>\n",
       "      <th>Source</th>\n",
       "      <th>Time</th>\n",
       "      <th>Publish Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 ex-bank officials booked for cheating bank o...</td>\n",
       "      <td>The CBI on Saturday booked four former officia...</td>\n",
       "      <td>The New Indian Express</td>\n",
       "      <td>09:25:00</td>\n",
       "      <td>2017-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Supreme Court to go paperless in 6 months: CJI</td>\n",
       "      <td>Chief Justice JS Khehar has said the Supreme C...</td>\n",
       "      <td>Outlook</td>\n",
       "      <td>22:18:00</td>\n",
       "      <td>2017-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>At least 3 killed, 30 injured in blast in Sylh...</td>\n",
       "      <td>At least three people were killed, including a...</td>\n",
       "      <td>Hindustan Times</td>\n",
       "      <td>23:39:00</td>\n",
       "      <td>2017-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why has Reliance been barred from trading in f...</td>\n",
       "      <td>Mukesh Ambani-led Reliance Industries (RIL) wa...</td>\n",
       "      <td>Livemint</td>\n",
       "      <td>23:08:00</td>\n",
       "      <td>2017-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Was stopped from entering my own studio at Tim...</td>\n",
       "      <td>TV news anchor Arnab Goswami has said he was t...</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>23:24:00</td>\n",
       "      <td>2017-03-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c9a1eaa-75fb-45b9-a1ff-8027e98abd58')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-0c9a1eaa-75fb-45b9-a1ff-8027e98abd58 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-0c9a1eaa-75fb-45b9-a1ff-8027e98abd58');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-166a6fcc-8454-426c-ae09-71926952f761\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-166a6fcc-8454-426c-ae09-71926952f761')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-166a6fcc-8454-426c-ae09-71926952f761 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                            Headline  \\\n",
       "0  4 ex-bank officials booked for cheating bank o...   \n",
       "1     Supreme Court to go paperless in 6 months: CJI   \n",
       "2  At least 3 killed, 30 injured in blast in Sylh...   \n",
       "3  Why has Reliance been barred from trading in f...   \n",
       "4  Was stopped from entering my own studio at Tim...   \n",
       "\n",
       "                                               Short                 Source   \\\n",
       "0  The CBI on Saturday booked four former officia...  The New Indian Express   \n",
       "1  Chief Justice JS Khehar has said the Supreme C...                 Outlook   \n",
       "2  At least three people were killed, including a...         Hindustan Times   \n",
       "3  Mukesh Ambani-led Reliance Industries (RIL) wa...                Livemint   \n",
       "4  TV news anchor Arnab Goswami has said he was t...                 YouTube   \n",
       "\n",
       "      Time  Publish Date  \n",
       "0  09:25:00   2017-03-26  \n",
       "1  22:18:00   2017-03-25  \n",
       "2  23:39:00   2017-03-25  \n",
       "3  23:08:00   2017-03-25  \n",
       "4  23:24:00   2017-03-25  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = pd.read_excel('/content/drive/MyDrive/InshortsData.xlsx')\n",
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "fm_zZps_mEh5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fm_zZps_mEh5",
    "outputId": "745e4632-9dae-4a88-a7a1-5537f6c991dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating summaries for test data...\n",
      "Processing 0/1000\n",
      "Processing 10/1000\n",
      "Processing 20/1000\n",
      "Processing 30/1000\n",
      "Processing 40/1000\n",
      "Processing 50/1000\n",
      "Processing 60/1000\n",
      "Processing 70/1000\n",
      "Processing 80/1000\n",
      "Processing 90/1000\n",
      "Processing 100/1000\n",
      "Processing 110/1000\n",
      "Processing 120/1000\n",
      "Processing 130/1000\n",
      "Processing 140/1000\n",
      "Processing 150/1000\n",
      "Processing 160/1000\n",
      "Processing 170/1000\n",
      "Processing 180/1000\n",
      "Processing 190/1000\n",
      "Processing 200/1000\n",
      "Processing 210/1000\n",
      "Processing 220/1000\n",
      "Processing 230/1000\n",
      "Processing 240/1000\n",
      "Processing 250/1000\n",
      "Processing 260/1000\n",
      "Processing 270/1000\n",
      "Processing 280/1000\n",
      "Processing 290/1000\n",
      "Processing 300/1000\n",
      "Processing 310/1000\n",
      "Processing 320/1000\n",
      "Processing 330/1000\n",
      "Processing 340/1000\n",
      "Processing 350/1000\n",
      "Processing 360/1000\n",
      "Processing 370/1000\n",
      "Processing 380/1000\n",
      "Processing 390/1000\n",
      "Processing 400/1000\n",
      "Processing 410/1000\n",
      "Processing 420/1000\n",
      "Processing 430/1000\n",
      "Processing 440/1000\n",
      "Processing 450/1000\n",
      "Processing 460/1000\n",
      "Processing 470/1000\n",
      "Processing 480/1000\n",
      "Processing 490/1000\n",
      "Processing 500/1000\n",
      "Processing 510/1000\n",
      "Processing 520/1000\n",
      "Processing 530/1000\n",
      "Processing 540/1000\n",
      "Processing 550/1000\n",
      "Processing 560/1000\n",
      "Processing 570/1000\n",
      "Processing 580/1000\n",
      "Processing 590/1000\n",
      "Processing 600/1000\n",
      "Processing 610/1000\n",
      "Processing 620/1000\n",
      "Processing 630/1000\n",
      "Processing 640/1000\n",
      "Processing 650/1000\n",
      "Processing 660/1000\n",
      "Processing 670/1000\n",
      "Processing 680/1000\n",
      "Processing 690/1000\n",
      "Processing 700/1000\n",
      "Processing 710/1000\n",
      "Processing 720/1000\n",
      "Processing 730/1000\n",
      "Processing 740/1000\n",
      "Processing 750/1000\n",
      "Processing 760/1000\n",
      "Processing 770/1000\n",
      "Processing 780/1000\n",
      "Processing 790/1000\n",
      "Processing 800/1000\n",
      "Processing 810/1000\n",
      "Processing 820/1000\n",
      "Processing 830/1000\n",
      "Processing 840/1000\n",
      "Processing 850/1000\n",
      "Processing 860/1000\n",
      "Processing 870/1000\n",
      "Processing 880/1000\n",
      "Processing 890/1000\n",
      "Processing 900/1000\n",
      "Processing 910/1000\n",
      "Processing 920/1000\n",
      "Processing 930/1000\n",
      "Processing 940/1000\n",
      "Processing 950/1000\n",
      "Processing 960/1000\n",
      "Processing 970/1000\n",
      "Processing 980/1000\n",
      "Processing 990/1000\n",
      "\n",
      "Evaluation Results:\n",
      "rouge1: 0.2814\n",
      "rouge2: 0.1039\n",
      "rougeL: 0.2409\n",
      "\n",
      "Sample Summaries:\n",
      "Article: The CBI on Saturday booked four former officials of Syndicate Bank and six others for cheating, forg...\n",
      "Original Headline: 4 ex-bank officials booked for cheating bank of ₹209 crore\n",
      "Generated Summary: the cbi booked four former officials of syndicate bank and six others the accused had availed home loans and credit from syndicate bank on the basis of forged and fabricated documents\n",
      "--------------------------------------------------\n",
      "Article: Chief Justice JS Khehar has said the Supreme Court will go paperless in six to seven months in a bid...\n",
      "Original Headline: Supreme Court to go paperless in 6 months: CJI\n",
      "Generated Summary: chief justice js khehar says supreme court will paperless in six to seven months supreme court will collect all records from lower courts so there is no need to file hard copies\n",
      "--------------------------------------------------\n",
      "Article: At least three people were killed, including a policeman, while 30 others were wounded on Saturday e...\n",
      "Original Headline: At least 3 killed, 30 injured in blast in Sylhet, Bangladesh\n",
      "Generated Summary: a policeman was killed in two explosions in sylhet bangladesh people were witnessing an over hourlong gunfight between extremists and commandos\n",
      "--------------------------------------------------\n",
      "Article: Mukesh Ambani-led Reliance Industries (RIL) was barred from trading in futures market for a year ove...\n",
      "Original Headline: Why has Reliance been barred from trading in futures?\n",
      "Generated Summary: reliance industries ril was barred from trading in futures market for a year over stake sale in reliance petroleum rpl in ril sold stake in rpl but shares were first shortsold in futures market to avoid a fall in rpl stocks\n",
      "--------------------------------------------------\n",
      "Article: TV news anchor Arnab Goswami has said he was told he could not do the programme two days before leav...\n",
      "Original Headline: Was stopped from entering my own studio at Times Now: Arnab\n",
      "Generated Summary: tv news anchor arnab goswami said he was told he could not do the programme two days before leaving times now th november was my last day i was not allowed to enter my own studio\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_dataset = pd.read_excel('/content/drive/MyDrive/InshortsData.xlsx')\n",
    "\n",
    "# Function to generate summary\n",
    "def generate_summary(text):\n",
    "    # Clean text\n",
    "    cleaned_text = clean_words(text)\n",
    "\n",
    "    # Prepare input\n",
    "    input_text = f\"summarize: {cleaned_text}\"\n",
    "    encoding = tokenizer(\n",
    "        input_text,\n",
    "        max_length=MAX_LENGTH,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # Move input to device\n",
    "    input_ids = encoding.input_ids.to(device)\n",
    "    attention_mask = encoding.attention_mask.to(device)\n",
    "\n",
    "    # Generate summary\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_length=150,\n",
    "            num_beams=4,\n",
    "            length_penalty=2.0,\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "    # Decode summary\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Generate summaries for test data\n",
    "test_articles = test_dataset['Short'].tolist()\n",
    "test_headlines = test_dataset['Headline'].tolist()\n",
    "test_articles = test_articles[:1000]\n",
    "test_headlines = test_headlines[:1000]\n",
    "generated_summaries = []\n",
    "\n",
    "print(\"Generating summaries for test data...\")\n",
    "for i, article in enumerate(test_articles):\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Processing {i}/{len(test_articles)}\")\n",
    "\n",
    "    if pd.isna(article):\n",
    "        generated_summaries.append(\"\")\n",
    "        continue\n",
    "\n",
    "    summary = generate_summary(article)\n",
    "    generated_summaries.append(summary)\n",
    "\n",
    "\n",
    "# Compute ROUGE metrics\n",
    "results = rouge.compute(\n",
    "    predictions=generated_summaries,\n",
    "    references=test_headlines,\n",
    "    use_stemmer=True,\n",
    "    rouge_types=['rouge1', 'rouge2', 'rougeL']\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(\"\\nEvaluation Results:\")\n",
    "for metric, score in results.items():\n",
    "    print(f\"{metric}: {score:.4f}\")\n",
    "\n",
    "# Save results to file\n",
    "with open(f\"{OUT_DIR}/evaluation_results.txt\", \"w\") as f:\n",
    "    f.write(\"Evaluation Results:\\n\")\n",
    "    for metric, score in results.items():\n",
    "        f.write(f\"{metric}: {score:.4f}\\n\")\n",
    "\n",
    "# Sample outputs\n",
    "print(\"\\nSample Summaries:\")\n",
    "for i in range(min(5, len(test_articles))):\n",
    "    if pd.isna(test_articles[i]):\n",
    "        continue\n",
    "\n",
    "    print(f\"Article: {test_articles[i][:100]}...\")\n",
    "    print(f\"Original Headline: {test_headlines[i]}\")\n",
    "    print(f\"Generated Summary: {generated_summaries[i]}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "XjMTG1TK89S9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XjMTG1TK89S9",
    "outputId": "7f7c4051-144b-4949-d202-9693b61e3a7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Summaries:\n",
      "Article: Indian spinner Ravichandran Ashwin has broken the record for most wickets in a single Test season, taking his 79th this season during the Dharamsala Test against Australia on Saturday. Ashwin went past South African pacer Dale Steyn, who had claimed 78 wickets in 12 Tests in 2007-08. Ashwin has taken seven five-wicket hauls this season in 13 matches....\n",
      "Original Headline: Ashwin breaks record for most wickets in a Test season\n",
      "Generated Summary: indian spinner ravichandran ashwin has broken the record for most wickets this season ashwin took his th test against australia on saturday\n",
      "--------------------------------------------------\n",
      "Article: American amateur chemist Robert Cornelius took the first known photographic self-portrait in 1839, which is considered as the world&#39;s first selfie. To capture the photo, he set up the camera behind his family&#39;s silver-plating shop, removed the lens cap, ran into the frame and sat still, before covering the lens again. He titled it &#39;The first light Picture ever taken&#39;....\n",
      "Original Headline: World&#39;s first selfie was taken in 1839\n",
      "Generated Summary: robert cornelius set up the camera behind his familys shop in silverplating he removed the lens cap ran into the frame and sat still before covering the lens\n",
      "--------------------------------------------------\n",
      "Article: Twinkle Khanna has said that Uttar Pradesh Chief Minister Yogi Adityanath needs to do an asana which helps in releasing gas. Twinkle said this when asked to give her views on Adityanath and his comments on women. Recently, an FIR was filed against filmmaker Shirish Kunder after he said that Adityanath&#39;s appointment was like Dawood being made the CBI director....\n",
      "Original Headline: Yogi Adityanath needs to do a gas-releasing asana: Twinkle\n",
      "Generated Summary: twinkle khanna said yogi adityanath needs to do an asana to release gas twinkle khanna said adityanaths appointment was like dawood being made the cbi director\n",
      "--------------------------------------------------\n",
      "Article: The World Wildlife Fund for Nature observed the 10th anniversary of &#39;Earth Hour&#39; on Saturday. The worldwide event is held annually encouraging individuals to turn off non-essential lights for one hour, from 8:30 to 9:30 PM local time as a symbol of their commitment to the planet. It was started as a lights-off event in Sydney, Australia, in 2007....\n",
      "Original Headline: &#39;Earth Hour&#39; observed on Saturday at 8:30 PM\n",
      "Generated Summary: the world wildlife fund for nature celebrates the th anniversary of earth hour the event was started as a lightsoff event in sydney\n",
      "--------------------------------------------------\n",
      "Article: The newly elected BJP-led Manipur government has announced to end the stage of interview in direct recruitment for junior level posts in all departments under the state government with immediate effect. The state also decided to amend the existing recruitment rules for Grade III and IV posts accordingly, an official statement said....\n",
      "Original Headline: Manipur government ends interviews for junior level posts\n",
      "Generated Summary: the newly elected bjpled manipur government announces to end the stage of interview in direct recruitment for junior level posts the state also decided to amend the existing recruitment rules for grade iii and iv posts\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Sample outputs\n",
    "print(\"\\nSample Summaries:\")\n",
    "for i in range(min(5, len(test_articles))):\n",
    "    if pd.isna(test_articles[i]):\n",
    "        continue\n",
    "\n",
    "    print(f\"Article: {test_articles[i+100]}...\")\n",
    "    print(f\"Original Headline: {test_headlines[i+100]}\")\n",
    "    print(f\"Generated Summary: {generated_summaries[i+100]}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "tKun5KVp8a37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tKun5KVp8a37",
    "outputId": "58606feb-c194-4584-893f-25bd2ddce81e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating summaries for test data...\n",
      "Processing 0/1020\n",
      "Processing 100/1020\n",
      "Processing 200/1020\n",
      "Processing 300/1020\n",
      "Processing 400/1020\n",
      "Processing 500/1020\n",
      "Processing 600/1020\n",
      "Processing 700/1020\n",
      "Processing 800/1020\n",
      "Processing 900/1020\n",
      "Processing 1000/1020\n",
      "\n",
      "Evaluation Results:\n",
      "rouge1: 0.3143\n",
      "rouge2: 0.1998\n",
      "rougeL: 0.2403\n",
      "\n",
      "Sample Summaries:\n",
      "Article: WorldCom trial starts in New York..The trial of Bernie Ebbers, former chief executive of bankrupt US...\n",
      "Original Headline: The trial of Bernie Ebbers, former chief executive of bankrupt US phone company WorldCom, has started in New York with the selection of the jury.Mr Ebbers, 63, is accused of being the mastermind behind an $11bn (£6bn) accounting fraud that eventually saw the firm collapse in July 2002.Under Mr Ebbers' leadership, WorldCom emerged from Mississippi obscurity to become a $160bn telecoms giant and the darling of late 1990s investors.Mr Ebbers' trial, which is expected to last two months, is the latest in a series of attempts by US prosecutors to pursue senior executives for fraud.If found guilty, Mr Ebbers could face a substantial jail sentence.\n",
      "Generated Summary: trial of bernie ebbers is expected to last two months trial is expected to coincide with retrial of former tyco international chief dennis kozlowski and his top lieutenant accused of looting the industrial conglomerate to the tune of m\n",
      "--------------------------------------------------\n",
      "Article: Crossrail link 'to get go-ahead'..The £10bn Crossrail transport plan, backed by business groups, is ...\n",
      "Original Headline: Jeremy de Souza, a spokesman for Crossrail, said on Sunday he could not confirm whether the Treasury was planning to invest £7.5bn or when the bill would go before Parliament.The £10bn Crossrail transport plan, backed by business groups, is to get the go-ahead this month, according to The Mail on Sunday.It says the UK Treasury has allocated £7.5bn ($13.99bn) for the project and that talks with business groups on raising the rest will begin shortly.The Mail on Sunday's Financial Mail said the £7.5bn of Treasury money was earmarked for spending in £2.5bn instalments in 2010, 2011 and 2012.\"We've always said we are going to introduce a hybrid Bill for Crossrail in the Spring and this remains the case,\" the Department for Transport said on Sunday.\n",
      "Generated Summary: bn crossrail transport plan is to get the goahead this month according to the mail on sundayit says the treasury has allocated bn for the project and that talks with business groups on raising the rest will begin shortly the treasury has allocated bn for the project\n",
      "--------------------------------------------------\n",
      "Article: Deutsche Boerse boosts dividend..Deutsche Boerse, the German stock exchange that is trying to buy it...\n",
      "Original Headline: Deutsche Boerse, the German stock exchange that is trying to buy its London rival, has said it will boost its 2004 dividend payment by 27%.Deutsche Boerse is \"trying to buy them off in a sense\", he said.\"Most of the disgruntled shareholders of Deutsche Boerse are complaining that the money that is being used for the bid could be better placed in their hands, paid out in dividends,\" Mr Faraj continued.Frankfurt-based Deutsche Boerse has offered £1.3bn ($2.48bn; 1.88bn euros) for the London Stock Exchange.Deutsche Boerse also said profit in the three months to 31 December was 120.7m euros ($158.8m; £83.3m).\n",
      "Generated Summary: deutsche boerse has offered bn bn bourse for the london stock exchange rival paneuropean bourse is also working on a bid late on monday deutsche boerse said it would lift its dividend payment to euro cents\n",
      "--------------------------------------------------\n",
      "Article: Iranian MPs threaten mobile deal..Turkey's biggest private mobile firm could bail out of a $3bn ($1....\n",
      "Original Headline: Conservatives in parliament say Turkcell's stake in Irancell, the new network, should be cut from 70% to 49%.Turkcell signed a contract for the new network in September.Iran currently has only one heavily congested mobile network, with long waiting lists for new subscribers.They say that Turkcell is a security risk because of alleged business ties with Israel.Turkcell said the ruling would \"make more difficult... Turkcell's financial consolidation of Irancell\" because its stake would be reduced to less than 50%.The firm has refused to comment on whether it has business dealings in Israel, although like almost all GSM operators worldwide it has an interconnection deal with Israeli networks so that its customers can use their phones there.Turkcell now says it may give up on the deal altogether.Telecoms is one of two areas specifically targeted by the new veto law on foreign investments, passed earlier in September.\n",
      "Generated Summary: turkcells stake in irancell should be cut from to they have already given themselves a veto over all foreign investment deals turkcell has only one heavily congested mobile network with long waiting lists for new subscribers turkcell signed a contract for the new network in september\n",
      "--------------------------------------------------\n",
      "Article: Euro firms miss out on optimism..More than 90% of large companies around the world are highly optimi...\n",
      "Original Headline: Possibly as a result, the worry about low-cost competition has slightly fallen from last year, with just 54% of companies calling it a \"significant threat\" or \"one of the biggest threats\".More than 90% of large companies around the world are highly optimistic about their economic prospects, a survey of 1,300 bosses suggests.When business advisers PricewaterhouseCoopers (PwC) conducted the same survey two years ago, nearly 30% of bosses were gloomy about their prospects.According to Frank Brown, global advisory leader at PwC , the trend of large companies to have global operations has one clear upside: \"One risk in one region - for example the Middle East - won't kill your business anymore.\"- For the survey, PricewaterhouseCoopers interviewed 1,324 chief executives throughout the world during the last three months of 2004.But PwC's global chief executive, Samuel DiPiazza, said a growing number of companies were also concerned that moves to outsource work to cheaper countries could both hurt their reputation in their home markets and harm the quality of service they provide to their customers.\n",
      "Generated Summary: pwc conducted the same survey two years ago nearly of bosses were gloomy about their prospects all stock exchangelisted companies are currently in the process of moving to new accounting standards called ifrs\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_dataset = pd.read_csv('/content/drive/MyDrive/bbc_news_dataset.csv')\n",
    "\n",
    "# Function to generate summary\n",
    "def generate_summary(text):\n",
    "    # Clean text\n",
    "    cleaned_text = clean_words(text)\n",
    "\n",
    "    # Prepare input\n",
    "    input_text = f\"summarize: {cleaned_text}\"\n",
    "    encoding = tokenizer(\n",
    "        input_text,\n",
    "        max_length=MAX_LENGTH,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # Move input to device\n",
    "    input_ids = encoding.input_ids.to(device)\n",
    "    attention_mask = encoding.attention_mask.to(device)\n",
    "\n",
    "    # Generate summary\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_length=150,\n",
    "            num_beams=4,\n",
    "            length_penalty=2.0,\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "    # Decode summary\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Generate summaries for test data\n",
    "test_articles = test_dataset['Articles'].tolist()\n",
    "test_headlines = test_dataset['Summaries'].tolist()\n",
    "test_articles = test_articles\n",
    "test_headlines = test_headlines\n",
    "generated_summaries = []\n",
    "\n",
    "print(\"Generating summaries for test data...\")\n",
    "for i, article in enumerate(test_articles):\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Processing {i}/{len(test_articles)}\")\n",
    "\n",
    "    if pd.isna(article):\n",
    "        generated_summaries.append(\"\")\n",
    "        continue\n",
    "\n",
    "    summary = generate_summary(article)\n",
    "    generated_summaries.append(summary)\n",
    "\n",
    "\n",
    "# Compute ROUGE metrics\n",
    "results = rouge.compute(\n",
    "    predictions=generated_summaries,\n",
    "    references=test_headlines,\n",
    "    use_stemmer=True,\n",
    "    rouge_types=['rouge1', 'rouge2', 'rougeL']\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(\"\\nEvaluation Results:\")\n",
    "for metric, score in results.items():\n",
    "    print(f\"{metric}: {score:.4f}\")\n",
    "\n",
    "# Save results to file\n",
    "with open(f\"{OUT_DIR}/evaluation_results.txt\", \"w\") as f:\n",
    "    f.write(\"Evaluation Results:\\n\")\n",
    "    for metric, score in results.items():\n",
    "        f.write(f\"{metric}: {score:.4f}\\n\")\n",
    "\n",
    "# Sample outputs\n",
    "print(\"\\nSample Summaries:\")\n",
    "for i in range(min(5, len(test_articles))):\n",
    "    if pd.isna(test_articles[i]):\n",
    "        continue\n",
    "\n",
    "    print(f\"Article: {test_articles[i][:100]}...\")\n",
    "    print(f\"Original Headline: {test_headlines[i]}\")\n",
    "    print(f\"Generated Summary: {generated_summaries[i]}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "wCRbSiwtEEvF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wCRbSiwtEEvF",
    "outputId": "4ffad8e8-aa55-4496-8e59-72c194599572"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Summaries:\n",
      "Article: Absa and Barclays talks continue..South Africa biggest retail bank Absa has said it is still in talks with UK bank Barclays over the sale of majority stake in the group...In November, Absa said it was close to striking a deal with Barclays. But the group said Barclays is still waiting for the approval of South Africa's banking and competition authorities to make a formal offer. Absa also announced that it expects to see earnings grow by 20-25% in its current financial year...\"Discussions with Barclays are continuing, but shareholders are advised that no agreement has been reached as to any offer being made by Barclays to acquire a majority stake in Absa,\" Absa said in a statement. If Barclays buys a stake in Absa it will be one of the largest foreign investments in South Africa in recent years. Absa currently has a market value of about $8.5bn (£4.4bn). Analysts said Absa's earnings forecast was better than expected. However, the company warned that headline earnings growth would be trimmed by about four percentage points because of share options for a black economic empowerment transaction and a staff share incentive scheme. The South African group will release its results for the year to 31 March on 30 May....\n",
      "Original Headline: South Africa biggest retail bank Absa has said it is still in talks with UK bank Barclays over the sale of majority stake in the group.\"Discussions with Barclays are continuing, but shareholders are advised that no agreement has been reached as to any offer being made by Barclays to acquire a majority stake in Absa,\" Absa said in a statement.In November, Absa said it was close to striking a deal with Barclays.If Barclays buys a stake in Absa it will be one of the largest foreign investments in South Africa in recent years.\n",
      "Generated Summary: absa says it is still in talks with uk bank barclays over the sale of majority stake absa says it expects to see earnings grow by in the current financial yeardiscussions with barclays are continuing\n",
      "--------------------------------------------------\n",
      "Article: Crude oil prices back above $50..Cold weather across parts of the United States and much of Europe has pushed US crude oil prices above $50 a barrel for the first time in almost three months...Freezing temperatures and heavy snowfall have increased demand for heating fuel in the US, where stocks are low. Fresh falls in the value of the dollar helped carry prices above the $50 mark for the first time since November. A barrel of US crude oil closed up $2.80 to $51.15 in New York on Tuesday. Opec members said on Tuesday that it saw no reason to cut its output...Although below last year's peak of $55.67 a barrel, which was reached in October, prices are now well above 2004's average of $41.48...Brent crude also rose in London trading, adding $1.89 to $48.62 at the close. Much of western Europe and the north east of America has been shivering under unseasonably low temperatures in recent days. The decline in the US dollar to a five-week low against the euro has also served to inflate prices. \"The dollar moved sharply overnight and oil is following it,\" said Chris Furness, senior market strategist at 4Cast. \"If the dollar continues to weaken, oil will be obviously higher.\"..Several Opec members said a cut in production was unlikely, citing rising prices and strong demand for oil from Asia. \"I agree that we do not need to cut supply if the prices are as much as this,\" Fathi Bin Shatwan, Libya's oil minister, told Reuters. \"I do not think we need to cut unless the prices are falling below $35 a barrel,\" he added. Opec closely watches global stocks to ensure that there is not an excessive supply in the market. The arrival of spring in the northern hemisphere will focus attention on stockpiles of US crude and gasoline, which are up to 9% higher than at this time last year. Heavy stockpiles could help force prices lower when demand eases....\n",
      "Original Headline: Cold weather across parts of the United States and much of Europe has pushed US crude oil prices above $50 a barrel for the first time in almost three months.Several Opec members said a cut in production was unlikely, citing rising prices and strong demand for oil from Asia.A barrel of US crude oil closed up $2.80 to $51.15 in New York on Tuesday.\"I agree that we do not need to cut supply if the prices are as much as this,\" Fathi Bin Shatwan, Libya's oil minister, told Reuters.\"I do not think we need to cut unless the prices are falling below $35 a barrel,\" he added.The decline in the US dollar to a five-week low against the euro has also served to inflate prices.Freezing temperatures and heavy snowfall have increased demand for heating fuel in the US, where stocks are low.\n",
      "Generated Summary: cold weather has pushed us crude oil prices above a barrel for the first time since november opec said on tuesday that it saw no reason to cut its output opec said a cut in production was unlikely citing rising prices\n",
      "--------------------------------------------------\n",
      "Article: Industrial output falls in Japan..Japanese industrial output fell in October while unemployment rose, casting further doubt on the strength of the country's economic recovery...Production dropped 1.6% in October, reflecting a decline in exports, while unemployment levels edged up 0.1% to 4.7%, slightly higher than forecast. The economy has grown for six quarters but growth slowed dramatically in the last quarter amid weaker global demand. Japan's government remains optimistic due to strong domestic demand...Analysts had been forecasting a 0.1% rise in month on month industrial output...According to figures from the Ministry of Economy, Trade and Industry (METI), the decline was led by a fall in demand for electronic parts for mobile phones and digital televisions. Although inventories fell 0.7% month on month, they were 36% higher than a year ago. \"It's a sign that the economy's adjustment phase is stronger than expected,\" said Takashi Yamanaka, an economist with UFJ Bank. Japan downgraded its overall economic assessment earlier this month for the first time in a year...Growth slowed to 0.3% in the quarter ending September 30, down from 6.3% in the first quarter of 2004. Experts believe the economy -which stagnated for most of the 1990s -may be entering a softer patch on the back of rising oil prices and the falling dollar. Japanese government officials played down the latest data, arguing that domestic consumer demand was still resilient. \"The outlook for November is positive so I don't think one can say that conditions have worsened just because of the fall in October,\" said a METI official. Despite the rise in unemployment, jobless figures are still some way below historical highs of recent years. The comparatively weak economic date preyed on shares with the Nikkei down 1% in afternoon trade....\n",
      "Original Headline: The economy has grown for six quarters but growth slowed dramatically in the last quarter amid weaker global demand.Japanese industrial output fell in October while unemployment rose, casting further doubt on the strength of the country's economic recovery.Analysts had been forecasting a 0.1% rise in month on month industrial output.According to figures from the Ministry of Economy, Trade and Industry (METI), the decline was led by a fall in demand for electronic parts for mobile phones and digital televisions.Although inventories fell 0.7% month on month, they were 36% higher than a year ago.Japanese government officials played down the latest data, arguing that domestic consumer demand was still resilient.\n",
      "Generated Summary: industrial output falls in japan in october while unemployment levels up to slightly higher than forecast the economy has grown for six quarters but growth slowed dramatically\n",
      "--------------------------------------------------\n",
      "Article: Bad weather hits Nestle sales..A combination of bad weather, rising raw material costs and the sluggish European economy has hit sales at Swiss food and drink giant Nestle...Revenue dipped 1.4% to 86.7bn Swiss francs ($74.6bn; £39.1bn) in 2004 as sales of ice cream and mineral water were dampened by the wet summer. However, Nestle's profits margins were helped by a strong performance in the Americas and China. Nestle is to raise its dividend by 11% after paying back some of its debt...Nestle said that the strength of the Swiss franc against the US dollar, the disposal of businesses and challenging trading conditions in Europe all dented sales. A poor summer across the continent - in contrast to the prolonged heat wave in 2003 - \"severely affected\" demand for ice cream. Sales of bottled water also fell, although chocolate, coffee, frozen goods and petcare products performed better...Elsewhere, Nestle said it had enjoyed an \"exceptional\" year in North America, outperforming the market in terms of sales growth. Nestle added that it had performed strongly in Africa and Asia despite the impact of high oil prices and political instability. Nestle's total earnings before interest remained broadly flat over the past year, despite the company managing to boost profit margins. As well as increasing its dividend, Nestle plans to buy back shares worth 1bn Swiss francs ($861m; £451m). Looking forward, Nestle forecasts organic earnings growth of about 5% in 2005, although it warned that trading would remain just as competitive...Uncertainty remains over the future of Perrier, the iconic French mineral water owned by Nestle. Perrier has been locked in a long-standing dispute with unions about productivity levels at the business, which has lead Nestle to consider selling the firm. \"The option of selling is Perrier is still on the table,\" chief executive Peter Brabeck-Letmathe confirmed on Thursday....\n",
      "Original Headline: As well as increasing its dividend, Nestle plans to buy back shares worth 1bn Swiss francs ($861m; £451m).Nestle said that the strength of the Swiss franc against the US dollar, the disposal of businesses and challenging trading conditions in Europe all dented sales.Uncertainty remains over the future of Perrier, the iconic French mineral water owned by Nestle.Nestle is to raise its dividend by 11% after paying back some of its debt.Revenue dipped 1.4% to 86.7bn Swiss francs ($74.6bn; £39.1bn) in 2004 as sales of ice cream and mineral water were dampened by the wet summer.Elsewhere, Nestle said it had enjoyed an \"exceptional\" year in North America, outperforming the market in terms of sales growth.\n",
      "Generated Summary: swiss food and drink giant nestlerevenue dipped to bn swiss francs bn in as sales of ice cream and mineral water were dampened by the wet summer swiss food and drink giants profits margins were helped by strong performance in the americas and china\n",
      "--------------------------------------------------\n",
      "Article: Brazil plays down Varig rescue..The Brazilian government has played down claims that it could step in to save the country's biggest airline...Brazil's airport authority chief Carlos Wilson had claimed the government was on the brink of stepping in to save Varig, Brazil's flagship airline. However, the country's vice president Jose Alencar has said the government still is looking for a solution. Varig is struggling under a huge debt burden of an estimated debt of 6.5 billion reais ($2.3bn or £1.2bn). Asked whether a rescue was on the cards following a meeting of the country's Congress to discuss the airline's crisis, Mr Alencar replied: \"No, I don't think so. We will see.\"..Earlier, Mr Wilson had said that president Luiz Inacio Lula da Silva has decided to step in and a decree of some kind of intervention could be signed this week. \"In practice, it will be an intervention, although this is not the technical name used\", he said. An intervention means that the government would take administrative control of the company and its finances. For that to happen Varig's main shareholder, the non-profit Ruben Berta Foundation which represents the airline's employees, would have to be removed, Mr Wilson said. However, no jobs would be lost and the airline would keep on flying, he added. Varig, which operates in 18 countries apart from Brazil, has been driven to the brink of collapse because of the country's economic downturn...The depreciation of Brazil's currency has had a direct impact on the airline's dollar debt as well as some of its costs. Business has improved recently with demand for air travel increasing and a recovery in the Brazilian economy. The airline could also win a sizeable windfall from a compensation claim against the government. On Tuesday the courts awarded Varig 2bn reais ($725m), after ruling in favour of its compensation claim against the government for freezing tariffs from 1985 to 1992. But the government can appeal the decision....\n",
      "Original Headline: The Brazilian government has played down claims that it could step in to save the country's biggest airline.However, the country's vice president Jose Alencar has said the government still is looking for a solution.The airline could also win a sizeable windfall from a compensation claim against the government.Brazil's airport authority chief Carlos Wilson had claimed the government was on the brink of stepping in to save Varig, Brazil's flagship airline.On Tuesday the courts awarded Varig 2bn reais ($725m), after ruling in favour of its compensation claim against the government for freezing tariffs from 1985 to 1992.Earlier, Mr Wilson had said that president Luiz Inacio Lula da Silva has decided to step in and a decree of some kind of intervention could be signed this week.An intervention means that the government would take administrative control of the company and its finances.\n",
      "Generated Summary: airport authority chief carlos wilson said the government was on the brink of stepping in to save varig varig is struggling under a huge debt burden of billion\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSample Summaries:\")\n",
    "for i in range(min(5, len(test_articles))):\n",
    "    if pd.isna(test_articles[i]):\n",
    "        continue\n",
    "\n",
    "    print(f\"Article: {test_articles[i+100]}...\")\n",
    "    print(f\"Original Headline: {test_headlines[i+100]}\")\n",
    "    print(f\"Generated Summary: {generated_summaries[i+100]}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "yAReOWEGEvF2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yAReOWEGEvF2",
    "outputId": "8f984b4d-0389-43d9-ba80-edf6593d851b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating summaries for custom inputs...\n",
      "Processing custom input 1/5\n",
      "Processing custom input 2/5\n",
      "Processing custom input 3/5\n",
      "Processing custom input 4/5\n",
      "Processing custom input 5/5\n",
      "\n",
      "Custom Generated Summaries:\n",
      "Input 1: Artificial intelligence is rapidly transforming industries worldwide. In healthcare, AI assists in d...\n",
      "Generated Summary: ai helps in diagnosing diseases and developing personalized treatments the financial sector uses ai for fraud detection and algorithmic trading transportation is seeing ai integration in autonomous vehicles\n",
      "--------------------------------------------------\n",
      "Input 2: Climate change poses a significant global threat. Rising temperatures lead to higher sea levels and ...\n",
      "Generated Summary: climate change poses a global threat rising temperatures lead to higher sea levels and more extreme weather events like hurricanes and droughts biodiversity is declining due to habitat loss and changing conditions\n",
      "--------------------------------------------------\n",
      "Input 3: Recent space exploration discoveries are expanding our understanding of the universe. Powerful new t...\n",
      "Generated Summary: the james webb space telescope provides detailed views of galaxies missions to mars probes suggest subsurface oceans could harbor life\n",
      "--------------------------------------------------\n",
      "Input 4: The global economy faces several challenges currently. Inflation is impacting purchasing power in ma...\n",
      "Generated Summary: disruptions caused by pandemic and geopolitical tensions complicate the economic outlook central banks are working to control inflation\n",
      "--------------------------------------------------\n",
      "Input 5: The shift towards renewable energy sources is accelerating globally. Solar and wind power are becomi...\n",
      "Generated Summary: the shift towards renewable energy sources is accelerating globally solar and wind power are becoming more efficient and costeffective investments in renewable energy infrastructure are increasing\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Your 5 custom inputs\n",
    "custom_inputs = [\n",
    "    \"Artificial intelligence is rapidly transforming industries worldwide. In healthcare, AI assists in diagnosing diseases and developing personalized treatments. The financial sector uses AI for fraud detection and algorithmic trading. Transportation is seeing AI integration in autonomous vehicles. While promising, the ethical implications and job market impact of AI are important considerations as its influence grows.\",\n",
    "\n",
    "    \"Climate change poses a significant global threat. Rising temperatures lead to higher sea levels and more extreme weather events like hurricanes and droughts. Biodiversity is declining due to habitat loss and changing conditions. Urgent action is needed globally to reduce greenhouse gas emissions by transitioning to renewable energy and adopting sustainable practices to protect the planet.\",\n",
    "\n",
    "    \"Recent space exploration discoveries are expanding our understanding of the universe. Powerful new telescopes like the James Webb Space Telescope provide detailed views of early galaxies. Missions to Mars are exploring its potential for life, while probes to moons like Europa suggest subsurface oceans that could harbor life. Private companies are accelerating space access with reusable rockets and ambitious mission plans.\",\n",
    "\n",
    "    \"The global economy faces several challenges currently. Inflation is impacting purchasing power in many countries. Supply chain disruptions, caused by the pandemic and geopolitical events, continue to affect the availability and cost of goods. Geopolitical tensions further complicate the economic outlook. Central banks are working to control inflation without causing a recession, as businesses adapt to navigate this complex environment.\",\n",
    "\n",
    "    \"The shift towards renewable energy sources is accelerating globally. Solar and wind power are becoming more efficient and cost-effective compared to fossil fuels. Investments in renewable energy infrastructure are increasing, supported by government policies. Advances in battery storage are improving the reliability of renewables. This transition is crucial for reducing emissions, improving air quality, and creating green jobs for a sustainable future.\"\n",
    "]\n",
    "# Generate summaries for custom inputs\n",
    "print(\"\\nGenerating summaries for custom inputs...\")\n",
    "custom_generated_summaries = []\n",
    "for i, text in enumerate(custom_inputs):\n",
    "    print(f\"Processing custom input {i+1}/{len(custom_inputs)}\")\n",
    "    summary = generate_summary(text)\n",
    "    custom_generated_summaries.append(summary)\n",
    "\n",
    "# Print custom generated summaries\n",
    "print(\"\\nCustom Generated Summaries:\")\n",
    "for i, summary in enumerate(custom_generated_summaries):\n",
    "    print(f\"Input {i+1}: {custom_inputs[i][:100]}...\")\n",
    "    print(f\"Generated Summary: {summary}\")\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5915.488545,
   "end_time": "2023-11-29T14:41:23.038520",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-29T13:02:47.549975",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
